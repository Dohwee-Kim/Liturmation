{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data는 김도휘 형제님과 김명찬 형제님이 만들어주신 보편지향 기도 데이터를 사용하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## CSV 에서 기도문 읽어오기\n",
    "def read_data(path_to_file):\n",
    "    df = pd.read_csv(path_to_file, dtype=str)\n",
    "    return df\n",
    "\n",
    "df = read_data('../../data/pray456_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/pray456_v3withid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "X = list(df['content'])\n",
    "y = list(df['label'])\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주님, 대림시기를 맞는 교회가 회개와 화해의 생활을 하며 저희에게  오실 아기 예수님을 기쁜 마음으로 맞이할 수 있도록 도와주소서.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['1', '2', '3', '4', '1']\n",
      "[0 1 2 3 0]\n",
      "[0 1 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(type(y[0]), y[:5])\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "print(integer_encoded[:5])\n",
    "y= integer_encoded\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619 155 619 155\n",
      "[3 2 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1212)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 619, 155, 155)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주님, 정신적 육체적으로 고통받는 형제들을 위하여 기도하오니  주님께서 몸소 그들을 위로하여 주시고  저희가 그들의 어려움을 함께 나누며 살아갈 수 있도록 도와주소서.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰 인덱싱 (token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 단어에 대한 idx 부여\n",
    "def convert_token_to_idx(token_ls):\n",
    "    for tokens in token_ls:\n",
    "        yield [token2idx[token] for token in tokens.split(' ')]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx = defaultdict(lambda : len(token2idx)) # token과 index를 매칭시켜주는 딕셔너리\n",
    "pad = token2idx['<PAD>']  # pytorch Variable로 변환하기 위해, 문장의 길이를 맞춰주기 위한 padding \n",
    "\n",
    "x_train = list(convert_token_to_idx(x_train))\n",
    "x_test = list(convert_token_to_idx(x_test))\n",
    "\n",
    "idx2token = {val : key for key,val in token2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱싱 결과 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 8,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원본 텍스트로 변환 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['주님,',\n",
       " '정신적',\n",
       " '육체적으로',\n",
       " '고통받는',\n",
       " '형제들을',\n",
       " '위하여',\n",
       " '기도하오니',\n",
       " '',\n",
       " '주님께서',\n",
       " '몸소',\n",
       " '그들을',\n",
       " '위로하여',\n",
       " '주시고',\n",
       " '',\n",
       " '저희가',\n",
       " '그들의',\n",
       " '어려움을',\n",
       " '함께',\n",
       " '나누며',\n",
       " '살아갈',\n",
       " '수',\n",
       " '있도록',\n",
       " '도와주소서.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2token[x] for x in x_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Variable로 변환하기 위해서는 모든 data의 길이(length)가 동일하여야 한다.\n",
    "# 영화 리뷰는 길이가 제각각이므로, 길이를 맞춰주는 작업을 수행\n",
    "# 짧은 문장에는 padding(공간을 채우기 위해 사용하는 더미)을 추가하고,\n",
    "# 긴 문장은 짤라서 줄인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Length를 맞추기 위한 padding\n",
    "def add_padding(token_ls, max_len):\n",
    "    for i, tokens in enumerate(token_ls):\n",
    "        n_token = len(tokens)\n",
    "        \n",
    "        # 길이가 짧으면 padding을 추가\n",
    "        if n_token < max_len:\n",
    "            token_ls[i] += [pad] * (max_len - n_token) # 부족한 만큼 padding을 추가함\n",
    "        \n",
    "        # 길이가 길면, max_len에서 짜름\n",
    "        elif n_token > max_len:\n",
    "            token_ls[i] = tokens[:max_len]\n",
    "    return token_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "x_train = add_padding(x_train, max_len)\n",
    "x_test = add_padding(x_test, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주님, 정신적 육체적으로 고통받는 형제들을 위하여 기도하오니  주님께서 몸소 그들을 위로하여 주시고  저희가 그들의 어려움을 함께 나누며 살아갈 수 있도록 도와주소서. <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2token[x] for x in x_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 모델 학습을 위해 Data의 type을 Variable 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch Variable로 변환\n",
    "def convert_to_long_variable(w2i_ls):\n",
    "    return Variable(torch.LongTensor(w2i_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = convert_to_long_variable(x_train)\n",
    "x_test = convert_to_long_variable(x_test)\n",
    "\n",
    "y_train = convert_to_long_variable(y_train)\n",
    "y_test = convert_to_long_variable(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  8, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, n_words, embed_size, pad_index, hid_size, dropout, n_class):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.n_words = n_words   # 고유한 토큰의 갯수\n",
    "        self.embed_size = embed_size   # 임베딩 차원의 크기\n",
    "        self.pad_index = pad_index     # 문장에 포함된 padding_token, embedding 과정에서 제외시킴\n",
    "        self.embed = nn.Embedding(n_words, embed_size, padding_idx=pad_index) # non-static embedding with Pytorch\n",
    "        \n",
    "        self.hid_size = hid_size    # Fully-Connet layer의 히든 레이어의 갯수\n",
    "        self.dropout = dropout   # 드롭아웃 비율\n",
    "        self.n_class = n_class   # 카테고리의 갯수\n",
    "\n",
    "#         pre-train된 embedding을 사용하고 싶다면,\n",
    "#         self.embed.weight = pre_trained_weight_matrix\n",
    "#         self.embed.weight.requires_grad = False  # embedding weight 고정 : static\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(embed_size, hid_size), nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size), nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size), nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hid_size, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embeded = self.embed(x)  # batch_size x sequence_length x embed_size\n",
    "\n",
    "        # 모든 단어의 embedding vector를 모두 더하여 sentence를 모델링한다.\n",
    "        x_cbow = x_embeded.sum(dim=1) # batch_size x 1 x embeded_size\n",
    "        x_cbow = x_cbow.squeeze(1)    # fully-connet를 위해, 1번째 차원을 축소\n",
    "\n",
    "        logit = self.lin(x_cbow)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_words' : len(token2idx),     # 고유한 토큰의 갯수\n",
    "    'embed_size' : 500,                 # embedding 차원의 크기\n",
    "    'pad_index' : token2idx['<PAD>'],  # embedding 과정에서 제외시킬, padding token\n",
    "    'hid_size' : 1000,                   # 히든 레이어 갯수\n",
    "    'dropout' : 0.5,                   # 드롭아웃 비율\n",
    "    'n_class' : 4,                     # 카테고리 갯수 (긍/부정)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embed): Embedding(3334, 500, padding_idx=0)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=1000, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr=0.001, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.87**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to %s'%(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 8.7e-05\n",
      "Epoch: 1 25.628804445266724 0.5625 tensor(192.2652, grad_fn=<NllLossBackward>) 0.567741935483871\n",
      "LR is set to 7.569e-05\n",
      "Epoch: 2 20.370041131973267 0.875 tensor(170.0465, grad_fn=<NllLossBackward>) 0.6193548387096774\n",
      "LR is set to 6.58503e-05\n",
      "Epoch: 3 15.623573184013367 0.625 tensor(144.1392, grad_fn=<NllLossBackward>) 0.7161290322580646\n",
      "LR is set to 5.7289760999999995e-05\n",
      "Epoch: 4 11.253332167863846 0.8125 tensor(125.8042, grad_fn=<NllLossBackward>) 0.7161290322580646\n",
      "LR is set to 4.984209207e-05\n",
      "Epoch: 5 8.51934415102005 0.875 tensor(119.5243, grad_fn=<NllLossBackward>) 0.6967741935483871\n",
      "LR is set to 4.3362620100900007e-05\n",
      "Epoch: 6 6.130872130393982 0.9375 tensor(109.9962, grad_fn=<NllLossBackward>) 0.7483870967741936\n",
      "LR is set to 3.7725479487783e-05\n",
      "Epoch: 7 4.594887092709541 1.0 tensor(109.4826, grad_fn=<NllLossBackward>) 0.7290322580645161\n",
      "LR is set to 3.282116715437121e-05\n",
      "Epoch: 8 3.541267551481724 0.9375 tensor(108.9555, grad_fn=<NllLossBackward>) 0.7290322580645161\n",
      "LR is set to 2.8554415424302954e-05\n",
      "Epoch: 9 2.6692899987101555 0.96875 tensor(109.1921, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 2.484234141914357e-05\n",
      "Epoch: 10 2.0552336424589157 1.0 tensor(110.0568, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 2.1612837034654905e-05\n",
      "Epoch: 11 1.8035609498620033 1.0 tensor(111.6489, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 1.8803168220149767e-05\n",
      "Epoch: 12 1.4441917687654495 1.0 tensor(112.1716, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 1.6358756351530297e-05\n",
      "Epoch: 13 1.3564286157488823 1.0 tensor(113.9212, grad_fn=<NllLossBackward>) 0.7290322580645161\n",
      "LR is set to 1.4232118025831359e-05\n",
      "Epoch: 14 1.1771815866231918 1.0 tensor(114.9249, grad_fn=<NllLossBackward>) 0.7419354838709677\n",
      "LR is set to 1.2381942682473281e-05\n",
      "Epoch: 15 1.085494089871645 1.0 tensor(114.7368, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 1.0772290133751755e-05\n",
      "Epoch: 16 0.955868300050497 1.0 tensor(115.2646, grad_fn=<NllLossBackward>) 0.7419354838709677\n",
      "LR is set to 9.371892416364026e-06\n",
      "Epoch: 17 0.8962585851550102 1.0 tensor(116.2085, grad_fn=<NllLossBackward>) 0.7354838709677419\n",
      "LR is set to 8.153546402236704e-06\n",
      "Epoch: 18 0.8485059589147568 1.0 tensor(116.9859, grad_fn=<NllLossBackward>) 0.7419354838709677\n",
      "LR is set to 7.0935853699459324e-06\n",
      "Epoch: 19 0.8093890585005283 1.0 tensor(117.4380, grad_fn=<NllLossBackward>) 0.7483870967741936\n",
      "LR is set to 6.1714192718529605e-06\n",
      "Epoch: 20 0.8218445517122746 1.0 tensor(117.9277, grad_fn=<NllLossBackward>) 0.7483870967741936\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "train_idx = np.arange(x_train.size(0))\n",
    "test_idx = np.arange(x_test.size(0))\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr)  # Adam Optimizer 사용\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')     # model이 logit을 반환하므로, 크로스-엔트로피-Loss를 사용,\n",
    "                                                     # 크로스-엔트로피-Loss는 Log_softmax + NLL_loss \n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    \n",
    "    # input 데이터 순서 섞기\n",
    "    random.shuffle(train_idx)\n",
    "    x_train = x_train[train_idx]\n",
    "    y_train = y_train[train_idx]\n",
    "    train_loss = 0\n",
    "\n",
    "    for start_idx, end_idx in zip(range(0, x_train.size(0), batch_size),\n",
    "                                  range(batch_size, x_train.size(0)+1, batch_size)):\n",
    "        x_batch = x_train[start_idx : end_idx]\n",
    "        y_batch = y_train[start_idx : end_idx].long()\n",
    "        \n",
    "        scores = model(x_batch)\n",
    "        predict = F.softmax(scores, dim=1).argmax(dim=1)\n",
    "        \n",
    "        train_acc = (predict == y_batch).sum().item() / batch_size\n",
    "        \n",
    "        loss = criterion(scores, y_batch)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= batch_size\n",
    "#     print('Train epoch : %s,  loss : %s,  accuracy :%.3f'%(epoch, train_loss / batch_size, train_acc))\n",
    "    \n",
    "    optimizer = adjust_learning_rate(optimizer, epoch, lr, 1) # adjust learning_rate while training\n",
    "    \n",
    "    model.eval()\n",
    "    scores = model(x_test)\n",
    "    predict = F.softmax(scores, dim=1).argmax(dim = 1)\n",
    "\n",
    "    acc = (predict == y_test).sum().item() / y_test.size(0)\n",
    "    loss = criterion(scores, y_test.long())\n",
    "\n",
    "#     print('Test Epoch : %s, Test Loss : %.03f , Test Accuracy : %.03f'%(epoch, loss.item()/y_test.size(0), acc))\n",
    "    print(\"Epoch:\", epoch, train_loss, train_acc, loss,  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

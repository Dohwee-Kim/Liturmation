{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data는 김도휘 형제님과 김명찬 형제님이 만들어주신 보편지향 기도 데이터를 사용하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## CSV 에서 기도문 읽어오기\n",
    "def read_data(path_to_file):\n",
    "    df = pd.read_csv(path_to_file, dtype=str)\n",
    "    return df\n",
    "\n",
    "df = read_data('../../data/pray456_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/pray456_v3withid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "X = list(df['content'])\n",
    "y = list(df['label'])\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주님, 대림시기를 맞는 교회가 회개와 화해의 생활을 하며 저희에게  오실 아기 예수님을 기쁜 마음으로 맞이할 수 있도록 도와주소서.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['1', '2', '3', '4', '1']\n",
      "[0 1 2 3 0]\n",
      "[0 1 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(type(y[0]), y[:5])\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "print(integer_encoded[:5])\n",
    "y= integer_encoded\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619 155 619 155\n",
      "[3 2 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1212)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 619, 155, 155)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주님, 정신적 육체적으로 고통받는 형제들을 위하여 기도하오니  주님께서 몸소 그들을 위로하여 주시고  저희가 그들의 어려움을 함께 나누며 살아갈 수 있도록 도와주소서.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 2877)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8193548387096774\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93        38\n",
      "          1       0.89      0.79      0.84        42\n",
      "          2       0.80      0.78      0.79        41\n",
      "          3       0.71      0.71      0.71        34\n",
      "\n",
      "avg / total       0.82      0.82      0.82       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ',accuracy)\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Pytorch MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 10  # how many epochs to train for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to np array\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'> [3 2 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train), x_train[:5])\n",
    "print(type(y_train), y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([619, 2877]) torch.Size([155, 2877])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmc55\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Converto torch tensor\n",
    "x_train, y_train, x_test, y_test = map(\n",
    "    torch.tensor, (x_train, y_train, x_test, y_test)\n",
    ")\n",
    "\n",
    "x_train = x_train.float()\n",
    "x_test = x_test.float()\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_hidden = nn.Linear(2877,2000)\n",
    "        self.relu = nn.ReLU() # instead of Heaviside step fn\n",
    "        self.fc_output = nn.Linear(2000, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc_hidden(x)\n",
    "        output = self.relu(output) # instead of Heaviside step fn\n",
    "        output = self.fc_output(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def accuracy(out, y):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == y).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0061,  0.0070, -0.0039,  ...,  0.0146,  0.0164,  0.0029],\n",
      "        [-0.0155,  0.0058, -0.0077,  ...,  0.0048, -0.0105, -0.0028],\n",
      "        [-0.0142, -0.0164,  0.0131,  ...,  0.0051,  0.0110, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0040,  0.0032,  0.0037,  ...,  0.0106, -0.0078, -0.0070],\n",
      "        [-0.0165,  0.0021,  0.0096,  ..., -0.0127,  0.0133, -0.0153],\n",
      "        [ 0.0063, -0.0147, -0.0052,  ..., -0.0167,  0.0061,  0.0004]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0058,  0.0171,  0.0057,  ..., -0.0184, -0.0048, -0.0126],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0015,  0.0113,  0.0058,  ..., -0.0176,  0.0194, -0.0005],\n",
      "        [ 0.0020,  0.0025,  0.0067,  ..., -0.0087, -0.0220,  0.0061],\n",
      "        [-0.0126,  0.0159, -0.0052,  ...,  0.0121, -0.0117, -0.0155],\n",
      "        [-0.0158, -0.0111,  0.0079,  ...,  0.0091,  0.0208,  0.0061]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0166,  0.0134, -0.0066, -0.0065], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MultiLayerPerceptron()\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 tensor(88.1919, grad_fn=<NllLossBackward>) tensor(0.2633) tensor(85.6346, grad_fn=<NllLossBackward>) tensor(0.2452)\n",
      "Epoch: 1 tensor(356.3346, grad_fn=<NllLossBackward>) tensor(0.6252) tensor(325.7858, grad_fn=<NllLossBackward>) tensor(0.4323)\n",
      "Epoch: 2 tensor(332.7526, grad_fn=<NllLossBackward>) tensor(0.5089) tensor(393.7271, grad_fn=<NllLossBackward>) tensor(0.4968)\n",
      "Epoch: 3 tensor(69.9571, grad_fn=<NllLossBackward>) tensor(0.7318) tensor(172.0058, grad_fn=<NllLossBackward>) tensor(0.6387)\n",
      "Epoch: 4 tensor(3.3112, grad_fn=<NllLossBackward>) tensor(0.9661) tensor(101.9493, grad_fn=<NllLossBackward>) tensor(0.7290)\n",
      "Epoch: 5 tensor(0.7965, grad_fn=<NllLossBackward>) tensor(0.9935) tensor(82.6395, grad_fn=<NllLossBackward>) tensor(0.7355)\n",
      "Epoch: 6 tensor(0.6857, grad_fn=<NllLossBackward>) tensor(0.9919) tensor(81.1506, grad_fn=<NllLossBackward>) tensor(0.7419)\n",
      "Epoch: 7 tensor(0.8406, grad_fn=<NllLossBackward>) tensor(0.9855) tensor(86.5473, grad_fn=<NllLossBackward>) tensor(0.7226)\n",
      "Epoch: 8 tensor(0.6614, grad_fn=<NllLossBackward>) tensor(0.9838) tensor(94.1679, grad_fn=<NllLossBackward>) tensor(0.7032)\n",
      "Epoch: 9 tensor(0.1367, grad_fn=<NllLossBackward>) tensor(0.9952) tensor(99.5755, grad_fn=<NllLossBackward>) tensor(0.7032)\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    \n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log\n",
    "    val_loss = criterion(model(x_test), y_test)\n",
    "    print(\"Epoch:\", epoch, criterion(model(x_train), y_train), accuracy(model(x_train), y_train), criterion(model(x_test), y_test), accuracy(model(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data는 e9t(Lucy Park)님께서 github에 공유해주신 네이버 영화평점 데이터를 사용하였습니다.\n",
    "# https://github.com/e9t/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data를 읽어오는 함수\n",
    "def read_txt(path_to_file):\n",
    "    txt_ls = []\n",
    "    label_ls = []\n",
    "\n",
    "    with open(path_to_file) as f:\n",
    "        for i, line in enumerate(f.readlines()[1:]):\n",
    "            _, txt, label = line.split('\\t')\n",
    "            txt_ls.append(txt)\n",
    "            label_ls.append(int(label.replace('\\n','')))\n",
    "\n",
    "    return txt_ls, label_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_txt('../ratings_train.txt')\n",
    "x_test, y_test = read_txt('../ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 150000, 50000, 50000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 더빙.. 진짜 짜증나네요 목소리'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이프라인 (Pipeline) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 162 out of 162 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'clf__solver': ('lbfgs', 'saga', 'newton-cg'), 'tfidf__max_df': (0.1, 0.25, 0.5), 'tfidf__ngram_range': ((1, 1), (1, 2), (1, 3)), 'tfidf__min_df': (1, 3, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'tfidf__ngram_range' : ((1,1),(1,2),(1,3)),\n",
    "    'tfidf__min_df' : (1, 3,10),\n",
    "    'tfidf__max_df' : (0.1, 0.25, 0.5),\n",
    "    'clf__solver' : ('lbfgs', 'saga', 'newton-cg')\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=2, n_jobs=4, verbose=10)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__solver': 'saga',\n",
       " 'tfidf__max_df': 0.25,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = best_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.81242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82     24827\n",
      "           1       0.83      0.78      0.81     25173\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     50000\n",
      "   macro avg       0.81      0.81      0.81     50000\n",
      "weighted avg       0.81      0.81      0.81     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ',accuracy)\n",
    "print(classification_report(y_test, predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fininsight_python_3.5",
   "language": "python",
   "name": "fininsight_python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
